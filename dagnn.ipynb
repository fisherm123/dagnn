{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ogb>=1.3.3 torch_geometric pyvis torch torch-scatter\n"
      ],
      "metadata": {
        "id": "mYUcgzmlYPY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch_geometric.data import DataLoader\n",
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import time\n",
        "from datetime import timedelta, datetime\n",
        "from torch.amp import GradScaler, autocast\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "ppWge21jD6kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_topological_layers(dataset):\n",
        "    processed_dataset = []\n",
        "\n",
        "    for data in dataset:\n",
        "        num_nodes = data.num_nodes\n",
        "        in_degree = torch.zeros(num_nodes, dtype=torch.long)\n",
        "\n",
        "        for _, dst in data.edge_index.T:\n",
        "            in_degree[dst] += 1\n",
        "\n",
        "        visited = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "        current_layer = (in_degree == 0).nonzero(as_tuple=False).view(-1)\n",
        "\n",
        "        topo_layers = torch.zeros(num_nodes, dtype=torch.long)\n",
        "\n",
        "        layer_idx = 0\n",
        "        while current_layer.numel() > 0:\n",
        "            topo_layers[current_layer] = layer_idx\n",
        "            visited[current_layer] = True\n",
        "\n",
        "            successors = []\n",
        "            for node in current_layer:\n",
        "                succ = data.edge_index[1][data.edge_index[0] == node]\n",
        "                successors.extend(succ.tolist())\n",
        "\n",
        "            for succ in successors:\n",
        "                in_degree[succ] -= 1\n",
        "\n",
        "            current_layer = (in_degree == 0).nonzero(as_tuple=False).view(-1)\n",
        "            current_layer = current_layer[~visited[current_layer]]\n",
        "            layer_idx += 1\n",
        "\n",
        "        data.topo_layers = topo_layers\n",
        "        processed_dataset.append(data)\n",
        "\n",
        "    return processed_dataset"
      ],
      "metadata": {
        "id": "hoNgKNdvXHJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_list, labels, mask_indices):\n",
        "        self.data_list = []\n",
        "        self.labels = []\n",
        "        self.mask_indices = []\n",
        "\n",
        "        for data, label, mask_idx in zip(data_list, labels, mask_indices):\n",
        "            if mask_idx < data.num_nodes:\n",
        "                self.data_list.append(data)\n",
        "                self.labels.append(label)\n",
        "                self.mask_indices.append(mask_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        data.x = data.x.type(torch.float)\n",
        "        data.y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        data.mask_index = torch.tensor(self.mask_indices[idx], dtype=torch.long)\n",
        "        return data"
      ],
      "metadata": {
        "id": "oXMA1wMA-W_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_node_token(data, mask_token_id=-1):\n",
        "    node_count = data.x.size(0)\n",
        "\n",
        "    mask_idx = random.randint(0, node_count - 1)\n",
        "    original_token = data.x[mask_idx, 0].clone()\n",
        "    masked_data = data.clone()\n",
        "    masked_data.x[mask_idx] = mask_token_id\n",
        "\n",
        "    return masked_data, original_token, mask_idx"
      ],
      "metadata": {
        "id": "F5eBtTtwR4pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_splits(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "\n",
        "    total_size = len(dataset)\n",
        "    indices = list(range(total_size))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    train_size = int(train_ratio * total_size)\n",
        "    val_size = int(val_ratio * total_size)\n",
        "\n",
        "    train_indices = indices[:train_size]\n",
        "    val_indices = indices[train_size:train_size + val_size]\n",
        "    test_indices = indices[train_size + val_size:]\n",
        "\n",
        "    train_dataset = [dataset[i] for i in train_indices]\n",
        "    val_dataset = [dataset[i] for i in val_indices]\n",
        "    test_dataset = [dataset[i] for i in test_indices]\n",
        "\n",
        "    print(f\"set sizes: - train: {len(train_dataset)}, val: {len(val_dataset)}, test: {len(test_dataset)}\")\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n"
      ],
      "metadata": {
        "id": "ba8grEaNhOfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(dataset_name='ogbg-code2', sample_ratio=1):\n",
        "    pyg_dataset = PygGraphPropPredDataset(name=dataset_name)\n",
        "    split_index = pyg_dataset.get_idx_split()\n",
        "\n",
        "    train_indices = split_index['train']\n",
        "    train_subset_indices = random.sample(\n",
        "        train_indices.tolist(),\n",
        "        max(1, int(len(train_indices) * sample_ratio))\n",
        "    )\n",
        "    dataset_subset = [pyg_dataset[i] for i in train_subset_indices]\n",
        "    print(f\"Number of graphs in subset: {len(dataset_subset)}\")\n",
        "\n",
        "    print(\"Computing topological batches\")\n",
        "    dataset_subset = preprocess_topological_layers(dataset_subset)\n",
        "\n",
        "    print(\"Applying masking to nodes\")\n",
        "    masked_data = []\n",
        "    labels = []\n",
        "    mask_indices = []\n",
        "\n",
        "    for data in dataset_subset:\n",
        "        masked_data_item, original_token, mask_idx = mask_node_token(data)\n",
        "        if mask_idx < data.num_nodes:\n",
        "            masked_data.append(masked_data_item)\n",
        "            labels.append(int(original_token.item()))\n",
        "            mask_indices.append(mask_idx)\n",
        "\n",
        "    print(\"Creating dataset\")\n",
        "    masked_dataset = MaskedDataset(masked_data, labels, mask_indices)\n",
        "\n",
        "    print(\"Creating splits\")\n",
        "    train_data, val_data, test_data = create_data_splits(masked_dataset)\n",
        "\n",
        "    batch_size = 128\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    vocab_size = get_max_vocab_size(train_loader)\n",
        "    print(f\"Vocab size: {vocab_size}\")\n",
        "\n",
        "    return {\n",
        "        'train_loader': train_loader,\n",
        "        'val_loader': val_loader,\n",
        "        'test_loader': test_loader,\n",
        "        'vocab_size': vocab_size\n",
        "    }"
      ],
      "metadata": {
        "id": "OL5cIxSdhNWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_scatter import scatter_add, scatter_softmax\n",
        "\n",
        "class DAGNNLayer(nn.Module):\n",
        "    def __init__(self, in_channels: int, hidden_channels: int, dropout_rate: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(in_channels)\n",
        "\n",
        "        self.query = nn.Linear(in_channels, hidden_channels)\n",
        "        self.key = nn.Linear(in_channels, hidden_channels)\n",
        "        self.value = nn.Linear(in_channels, hidden_channels)\n",
        "\n",
        "        self.norm2 = nn.LayerNorm(hidden_channels)\n",
        "\n",
        "        self.gru = nn.GRUCell(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.output_proj = nn.Linear(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def attention_for_layer(self, x, edge_index, current_nodes, prev_nodes):\n",
        "        dst_mask = torch.isin(edge_index[1], current_nodes)\n",
        "        src_mask = torch.isin(edge_index[0], prev_nodes)\n",
        "        mask = dst_mask & src_mask\n",
        "\n",
        "        if not mask.any():\n",
        "            return torch.zeros((len(current_nodes), x.size(1)), device=x.device)\n",
        "\n",
        "        layer_edges = edge_index[:, mask]\n",
        "        src, dst = layer_edges\n",
        "\n",
        "        q = self.query(x[dst])\n",
        "        k = self.key(x[src])\n",
        "        v = self.value(x[src])\n",
        "\n",
        "        scores = torch.sum(q * k, dim=-1) / torch.sqrt(torch.tensor(self.hidden_channels).float())\n",
        "\n",
        "        attention_weights = scatter_softmax(scores, dst, dim=0)\n",
        "\n",
        "        weighted_messages = v * attention_weights.unsqueeze(-1)\n",
        "        node_to_pos = {node.item(): idx for idx, node in enumerate(current_nodes)}\n",
        "        dst_positions = torch.tensor([node_to_pos[node.item()] for node in dst],\n",
        "                                   device=dst.device)\n",
        "\n",
        "        output = scatter_add(weighted_messages, dst_positions, dim=0,\n",
        "                           dim_size=len(current_nodes))\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, x, edge_index, topo_layers):\n",
        "        x = self.norm1(x)\n",
        "        identity = x\n",
        "\n",
        "        h = torch.zeros_like(x)\n",
        "        max_layer = topo_layers.max()\n",
        "\n",
        "        processed_nodes = torch.tensor([], dtype=torch.long, device=x.device)\n",
        "\n",
        "        for layer_idx in range(max_layer + 1):\n",
        "            current_nodes = (topo_layers == layer_idx).nonzero().squeeze(-1)\n",
        "            if len(current_nodes.shape) == 0 or current_nodes.nelement() == 0:\n",
        "                continue\n",
        "\n",
        "            # do attention for topological batch\n",
        "            messages = self.attention_for_layer(x, edge_index, current_nodes, processed_nodes)\n",
        "\n",
        "            h[current_nodes] = self.gru(x[current_nodes], messages)\n",
        "            x[current_nodes] = h[current_nodes]\n",
        "\n",
        "            processed_nodes = torch.cat([processed_nodes, current_nodes])\n",
        "\n",
        "        h = self.norm2(h)\n",
        "        h = self.output_proj(h)\n",
        "        h = self.dropout_layer(h)\n",
        "\n",
        "        return h + identity\n",
        "\n",
        "class DAGNN(nn.Module):\n",
        "    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int,\n",
        "                 num_layers: int = 2, dropout_rate: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embed = nn.Linear(in_channels, hidden_channels)\n",
        "\n",
        "        self.norm = nn.LayerNorm(hidden_channels)\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DAGNNLayer(\n",
        "                hidden_channels,\n",
        "                hidden_channels,\n",
        "                dropout_rate=dropout_rate\n",
        "            ) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_norm = nn.LayerNorm(hidden_channels)\n",
        "        self.output = nn.Sequential(\n",
        "            nn.Linear(hidden_channels, hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_channels, out_channels)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
        "                if module.bias is not None:\n",
        "                    nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        topo_layers = data.topo_layers\n",
        "\n",
        "        x = self.embed(x.float())\n",
        "        x = self.norm(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout_layer(x)\n",
        "\n",
        "        initial_x = x\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, edge_index, topo_layers)\n",
        "            x = F.relu(x)\n",
        "\n",
        "        x = x + initial_x\n",
        "\n",
        "        x = self.output_norm(x)\n",
        "        return self.output(x)"
      ],
      "metadata": {
        "id": "F909dBvdgDVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_vocab_size(train_loader):\n",
        "    max_target = 0\n",
        "    for batch in train_loader:\n",
        "        max_target = max(max_target, batch.y.max().item())\n",
        "    return max_target + 1"
      ],
      "metadata": {
        "id": "k5Aze72Rcxvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(11)\n",
        "torch.manual_seed(11)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(11)\n",
        "\n",
        "processed_data = preprocess_dataset()"
      ],
      "metadata": {
        "id": "tKjmKw5xkSti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    class_correct = defaultdict(int)\n",
        "    class_total = defaultdict(int)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            outputs = model(batch)\n",
        "\n",
        "            predictions = []\n",
        "            start_idx = 0\n",
        "            for i in range(batch.num_graphs):\n",
        "                num_nodes = int(torch.sum((batch.batch == i).int()))\n",
        "                mask_idx = min(int(batch.mask_index[i]), num_nodes - 1)\n",
        "                node_idx = start_idx + mask_idx\n",
        "                predictions.append(outputs[node_idx])\n",
        "                start_idx += num_nodes\n",
        "\n",
        "            predictions = torch.stack(predictions)\n",
        "            loss = criterion(predictions, batch.y).item()\n",
        "            total_loss += loss\n",
        "\n",
        "            preds = predictions.argmax(dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch.y.cpu().numpy())\n",
        "\n",
        "            for pred, true in zip(preds.cpu(), batch.y.cpu()):\n",
        "                class_total[true.item()] += 1\n",
        "                if pred == true:\n",
        "                    class_correct[true.item()] += 1\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    unique_classes = np.unique(all_labels)\n",
        "\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro', labels=unique_classes)\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None, labels=unique_classes)\n",
        "\n",
        "    f1_dict = dict(zip(unique_classes, f1_per_class))\n",
        "\n",
        "    total = sum(class_total.values())\n",
        "    correct = sum(class_correct.values())\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    class_metrics = {}\n",
        "    for class_idx in class_total.keys():\n",
        "        class_metrics[class_idx] = {\n",
        "            'accuracy': class_correct[class_idx] / class_total[class_idx],\n",
        "            'correct': class_correct[class_idx],\n",
        "            'total': class_total[class_idx],\n",
        "            'f1': f1_dict.get(class_idx, 0.0)\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        'loss': avg_loss,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_macro': f1_macro,\n",
        "        'class_metrics': class_metrics\n",
        "    }\n",
        "\n",
        "def train(model, train_loader, val_loader, test_loader, num_epochs, device, learning_rate=1e-3):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=1, verbose=True\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    val_f1_scores = []\n",
        "    learning_rates = []\n",
        "\n",
        "    best_val_f1 = 0.0\n",
        "    patience = 10\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        batch_correct = 0\n",
        "        batch_total = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(batch)\n",
        "            predictions = []\n",
        "            start_idx = 0\n",
        "\n",
        "            for i in range(batch.num_graphs):\n",
        "                num_nodes = int(torch.sum((batch.batch == i).int()))\n",
        "                mask_idx = min(int(batch.mask_index[i]), num_nodes - 1)\n",
        "                node_idx = start_idx + mask_idx\n",
        "                predictions.append(outputs[node_idx])\n",
        "                start_idx += num_nodes\n",
        "\n",
        "            predictions = torch.stack(predictions)\n",
        "            loss = criterion(predictions, batch.y)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            preds = predictions.argmax(dim=1)\n",
        "            batch_correct += (preds == batch.y).sum().item()\n",
        "            batch_total += len(batch.y)\n",
        "\n",
        "            train_losses.append(epoch_loss/(batch_idx + 1))\n",
        "            train_accuracies.append(batch_correct/batch_total)\n",
        "\n",
        "            if (batch_idx + 1) % 5 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}/{len(train_loader)}: \"\n",
        "                      f\"Loss = {epoch_loss/(batch_idx + 1):.4f}, \"\n",
        "                      f\"Accuracy = {batch_correct/batch_total:.4f}\")\n",
        "\n",
        "        val_metrics = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        val_losses.append(val_metrics['loss'])\n",
        "        val_accuracies.append(val_metrics['accuracy'])\n",
        "        val_f1_scores.append(val_metrics['f1_macro'])\n",
        "        learning_rates.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        scheduler.step(val_metrics['f1_macro'])\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Train Accuracy: {batch_correct/batch_total:.4f}\")\n",
        "        print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
        "        print(f\"Val F1 (macro): {val_metrics['f1_macro']:.4f}\")\n",
        "\n",
        "\n",
        "        if val_metrics['f1_macro'] > best_val_f1:\n",
        "            best_val_f1 = val_metrics['f1_macro']\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "            print(\"new best found\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"early stop\")\n",
        "                break\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(train_losses, label='Training')\n",
        "    plt.plot(np.linspace(0, len(train_losses), len(val_losses)), val_losses, label='Validation')\n",
        "    plt.title('Loss over Time')\n",
        "    plt.xlabel('Batch (Training) / Epoch (Validation)')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Training')\n",
        "    plt.plot(np.linspace(0, len(train_accuracies), len(val_accuracies)), val_accuracies, label='Validation')\n",
        "    plt.title('Accuracy over Time')\n",
        "    plt.xlabel('Batch (Training) / Epoch (Validation)')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(val_f1_scores)\n",
        "    plt.title('Validation F1 Macro Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(learning_rates)\n",
        "    plt.title('Learning Rate')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'training_curves.png')\n",
        "    plt.close()\n",
        "\n",
        "    model.load_state_dict(torch.load('best_model.pt'))\n",
        "    test_metrics = evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"\\nFinal Test Results:\")\n",
        "    print(f\"Test Loss: {test_metrics['loss']:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Test F1 (macro): {test_metrics['f1_macro']:.4f}\")\n",
        "\n",
        "    metrics = {\n",
        "        'train_losses': train_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'val_f1_scores': val_f1_scores,\n",
        "        'learning_rates': learning_rates,\n",
        "        'test_metrics': test_metrics\n",
        "    }\n",
        "\n",
        "    return model, test_metrics, metrics"
      ],
      "metadata": {
        "id": "mXDwfplvVHqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_save_directory():\n",
        "    save_dir = '/content/model_results'\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    return save_dir\n",
        "\n",
        "def save_run_metrics(model_name, run_id, metrics, save_dir):\n",
        "    \"\"\"Save metrics for a single run\"\"\"\n",
        "    results = {\n",
        "        'model_name': model_name,\n",
        "        'run_id': run_id,\n",
        "        'accuracy': metrics['accuracy'],\n",
        "        'f1_macro': metrics['f1_macro'],\n",
        "        'class_metrics': metrics['class_metrics']\n",
        "    }\n",
        "\n",
        "    filename = os.path.join(save_dir, f\"metrics_{model_name}_{run_id}.json\")\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results, f)\n",
        "    print(f\"Saved metrics to: {filename}\")\n",
        "\n",
        "def run_multiple_trainings(model_class, model_params, train_params, num_runs=3):\n",
        "    save_dir = setup_save_directory()\n",
        "    all_metrics = []\n",
        "    all_training_metrics = []\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        print(f\"\\nStarting Run {run + 1}/{num_runs}\")\n",
        "\n",
        "        model = model_class(**model_params).to('cuda')\n",
        "\n",
        "        trained_model, test_metrics, training_metrics = train(model=model, **train_params)\n",
        "\n",
        "        save_run_metrics('dagnn_main', run, test_metrics, save_dir)\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.plot(training_metrics['val_f1_scores'])\n",
        "        plt.title(f'Run {run + 1} Validation F1 Macro Score')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('F1 Score')\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(save_dir, f'val_f1_run_{run + 1}.png'))\n",
        "        plt.close()\n",
        "\n",
        "        all_metrics.append(test_metrics)\n",
        "        all_training_metrics.append(training_metrics)\n",
        "\n",
        "        print(f\"Run {run + 1} completed\")\n",
        "        print(f\"F1 Macro: {test_metrics['f1_macro']:.4f}\")\n",
        "\n",
        "    print(f\"\\nAll results saved in: {save_dir}\")\n",
        "    return all_metrics, all_training_metrics\n",
        "\n",
        "model_params = {\n",
        "    'in_channels': 2,\n",
        "    'hidden_channels': 64,\n",
        "    'out_channels': processed_data['vocab_size'],\n",
        "    'num_layers': 2,\n",
        "    'dropout_rate': 0.1\n",
        "}\n",
        "\n",
        "train_params = {\n",
        "    'train_loader': processed_data['train_loader'],\n",
        "    'val_loader': processed_data['val_loader'],\n",
        "    'test_loader': processed_data['test_loader'],\n",
        "    'num_epochs': 3,\n",
        "    'device': 'cuda',\n",
        "    'learning_rate': 1e-3\n",
        "}\n",
        "\n",
        "metrics_list, training_metrics_list = run_multiple_trainings(\n",
        "    model_class=DAGNN,\n",
        "    model_params=model_params,\n",
        "    train_params=train_params,\n",
        "    num_runs=3\n",
        ")"
      ],
      "metadata": {
        "id": "FtNc1boT-HKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparam_sensitivity():\n",
        "    learning_rates = [1e-2, 1e-3, 1e-4]\n",
        "    layer_counts = [2, 3, 4]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    base_model_params = {\n",
        "        'in_channels': 2,\n",
        "        'hidden_channels': 64,\n",
        "        'out_channels': processed_data['vocab_size'],\n",
        "        'dropout_rate': 0.1\n",
        "    }\n",
        "\n",
        "    base_train_params = {\n",
        "        'train_loader': processed_data['train_loader'],\n",
        "        'val_loader': processed_data['val_loader'],\n",
        "        'test_loader': processed_data['test_loader'],\n",
        "        'num_epochs': 3,\n",
        "        'device': 'cuda'\n",
        "    }\n",
        "\n",
        "    for lr in learning_rates:\n",
        "        for num_layers in layer_counts:\n",
        "            print(f\"training with lr={lr}, layers={num_layers}\")\n",
        "\n",
        "            model_params = base_model_params.copy()\n",
        "            model_params['num_layers'] = num_layers\n",
        "\n",
        "            train_params = base_train_params.copy()\n",
        "            train_params['learning_rate'] = lr\n",
        "\n",
        "            model = DAGNN(**model_params).to('cuda')\n",
        "            _, test_metrics, training_metrics = train_model_with_tracking(model=model, **train_params)\n",
        "\n",
        "            key = f\"lr={lr}_layers={num_layers}\"\n",
        "            results[key] = {\n",
        "                'test_metrics': test_metrics,\n",
        "                'training_metrics': training_metrics\n",
        "            }\n",
        "\n",
        "    plt.figure(figsize=(20, 15))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    for lr in learning_rates:\n",
        "        key = f\"lr={lr}_layers=2\"\n",
        "        metrics = results[key]['training_metrics']\n",
        "        plt.plot(metrics['val_f1_scores'], label=f'lr={lr}')\n",
        "    plt.title('Validation F1 Score vs Learning Rate (2 layers)')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    for layers in layer_counts:\n",
        "        key = f\"lr=0.001_layers={layers}\"\n",
        "        metrics = results[key]['training_metrics']\n",
        "        plt.plot(metrics['val_f1_scores'], label=f'{layers} layers')\n",
        "    plt.title('Validation F1 Score vs Number of Layers (lr=1e-3)')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    x = np.arange(len(learning_rates))\n",
        "    width = 0.25\n",
        "\n",
        "    for i, layers in enumerate(layer_counts):\n",
        "        f1_scores = [results[f\"lr={lr}_layers={layers}\"]['test_metrics']['f1_macro'] for lr in learning_rates]\n",
        "        plt.bar(x + i*width, f1_scores, width, label=f'{layers} layers')\n",
        "\n",
        "    plt.xlabel('Learning Rate')\n",
        "    plt.ylabel('Final F1 Score')\n",
        "    plt.title('Final F1 Score Comparison')\n",
        "    plt.xticks(x + width, [str(lr) for lr in learning_rates])\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    x = np.arange(len(learning_rates))\n",
        "\n",
        "    for i, layers in enumerate(layer_counts):\n",
        "        val_losses = [results[f\"lr={lr}_layers={layers}\"]['training_metrics']['val_losses'][-1] for lr in learning_rates]\n",
        "        plt.bar(x + i*width, val_losses, width, label=f'{layers} layers')\n",
        "\n",
        "    plt.xlabel('Learning Rate')\n",
        "    plt.ylabel('Final Validation Loss')\n",
        "    plt.title('Final Validation Loss Comparison')\n",
        "    plt.xticks(x + width, [str(lr) for lr in learning_rates])\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('hyperparameter_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    return results\n",
        "\n",
        "comparison_results = run_hyperparameter_comparison()\n",
        "\n",
        "best_f1 = 0\n",
        "best_config = None\n",
        "\n",
        "for key, result in comparison_results.items():\n",
        "    f1 = result['test_metrics']['f1_macro']\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_config = key\n",
        "\n",
        "print(f\"\\nBest configuration: {best_config}\")\n",
        "print(f\"Best F1 macro score: {best_f1:.4f}\")"
      ],
      "metadata": {
        "id": "8WAprPBbvUUk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}